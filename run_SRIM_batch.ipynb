{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import alpha_recoil_sim as ar\n",
    "import importlib, glob, os, shutil, subprocess, pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## first make a list of all the daughter isotopes we need\n",
    "path = \"/Users/dcmoore/Library/CloudStorage/GoogleDrive-david.c.moore@yale.edu/My Drive/yale/uspheres/alpha_recoils_Grimm/Sphere_Recoils_MC\"\n",
    "\n",
    "iso_list = ['Ac-225', 'Pb-212', 'At-211', 'Th-227', 'Ra-223', 'Po-216', 'He-4']\n",
    "\n",
    "iso_dict = {}\n",
    "\n",
    "for iso in iso_list:\n",
    "    ciso = iso[:2].lower()\n",
    "    cA = iso.split('-')[1]\n",
    "    iso_dict[iso] = ar.parse_decay_chain(path + \"/decay_data/\" + ciso + \"_\" + cA + \"_decay_chain.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$^{225}$Ac & $^{225}$Ac (5.8), $^{221}$Fr (6.3), $^{217}$At (7.1), $^{213}$Bi (5.9), $^{213}$Po (8.4) & $^{221}$Fr (105), $^{217}$At (116), $^{213}$Bi (132), $^{209}$Tl (112), $^{209}$Pb (160) \\\\ \n",
      "$^{212}$Pb & $^{212}$Bi (6.1), $^{212}$Po (8.8) & $^{208}$Tl (117), $^{208}$Pb (168) \\\\ \n",
      "$^{211}$At & $^{211}$At (5.9), $^{211}$Po (7.5) & $^{207}$Bi (113), $^{207}$Pb (143) \\\\ \n",
      "$^{227}$Th & $^{227}$Th (6.0), $^{223}$Ra (5.9), $^{219}$Rn (6.8), $^{215}$Po (7.4), $^{211}$Bi (6.6), $^{211}$Po (7.5) & $^{223}$Ra (108), $^{219}$Rn (107), $^{215}$Po (126), $^{211}$Pb (140), $^{207}$Tl (127), $^{207}$Pb (143) \\\\ \n",
      "$^{223}$Ra & $^{223}$Ra (5.9), $^{219}$Rn (6.8), $^{215}$Po (7.4), $^{211}$Bi (6.6), $^{211}$Po (7.5) & $^{219}$Rn (107), $^{215}$Po (126), $^{211}$Pb (140), $^{207}$Tl (127), $^{207}$Pb (143) \\\\ \n",
      "$^{216}$Po & $^{216}$Po (6.8), $^{212}$Bi (6.1), $^{212}$Po (8.8) & $^{212}$Pb (127), $^{208}$Tl (117), $^{208}$Pb (168) \\\\ \n",
      "$^{4}$He   \\\\ \n"
     ]
    }
   ],
   "source": [
    "## print latex table of major alphas for each isotope for the note\n",
    "alpha_mass=4\n",
    "for iso in iso_list:\n",
    "\n",
    "    full_list = iso_dict[iso].keys()\n",
    "    dlist = []\n",
    "    for k in full_list:\n",
    "        if 'decays' in k:\n",
    "            dlist.append(k[:6])\n",
    "\n",
    "    curr_nr_list = []\n",
    "    curr_nr_eng = []\n",
    "    curr_alpha_eng = []\n",
    "    curr_parents = []\n",
    "\n",
    "    for k in dlist:\n",
    "\n",
    "        decay = iso_dict[iso][k + \"_decays\"]\n",
    "        daught = iso_dict[iso][k + \"_daughters\"]\n",
    "\n",
    "        for j in range(len(daught)):\n",
    "            \n",
    "            if daught[j] not in curr_nr_list:\n",
    "                daughter_mass = float(daught[j].split(\"-\")[-1])\n",
    "                decay_NR_energy = decay[j,1] * alpha_mass/daughter_mass\n",
    "                if(decay_NR_energy > 0):\n",
    "                    curr_nr_list.append(daught[j])\n",
    "                    curr_nr_eng.append(decay_NR_energy)\n",
    "                    curr_alpha_eng.append(decay[j,1])\n",
    "                    curr_parents.append(k)\n",
    "\n",
    "    #print(iso, curr_nr_eng, curr_nr_list)\n",
    "    iso_mass = float(iso.split(\"-\")[-1])\n",
    "    iso_symb = iso.split(\"-\")[0]\n",
    "    s1 = \"$^{%d}$%s & \"%(iso_mass, iso_symb)\n",
    "    for j in range(len(curr_alpha_eng)):\n",
    "        cm = float(curr_parents[j].split(\"-\")[-1])\n",
    "        cs = curr_parents[j].split(\"-\")[0]\n",
    "        s1 += \"$^{%d}$%s (%.1f), \" % (cm, cs, curr_alpha_eng[j]/1000) \n",
    "\n",
    "    s1 = s1[:-2] #drop comma\n",
    "    s1 += \" & \"\n",
    "\n",
    "    for j in range(len(curr_nr_eng)):\n",
    "        cm = float(curr_nr_list[j].split(\"-\")[-1])\n",
    "        cs = curr_nr_list[j].split(\"-\")[0]\n",
    "        s1 += \"$^{%d}$%s (%d), \" % (cm, cs, curr_nr_eng[j]) \n",
    "\n",
    "    s1 = s1[:-2] #drop comma\n",
    "    s1 += \" \\\\\\\\ \"\n",
    "\n",
    "    print(s1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fr-221', 'At-217', 'Bi-213', 'Tl-209', 'Pb-209', 'Tl-208', 'Pb-208', 'Bi-207', 'Pb-207', 'Ra-223', 'Rn-219', 'Po-215', 'Pb-211', 'Tl-207', 'Pb-212', 'He-4']\n"
     ]
    }
   ],
   "source": [
    "## go through the dictionary and make a list of all alpha decay daughters we need SRIM simulations for\n",
    "daughter_list = []\n",
    "for iso in iso_list:\n",
    "    if(iso == \"He-4\"):\n",
    "        daughter_list.append(iso)\n",
    "        continue\n",
    "    \n",
    "    curr_dict = iso_dict[iso]\n",
    "    \n",
    "    curr_keys = curr_dict.keys()\n",
    "\n",
    "    for k in curr_keys:\n",
    "        if not '_daughters' in k: continue\n",
    "\n",
    "        curr_daught = curr_dict[k]\n",
    "        curr_alpha = curr_dict[k[:6] + \"_decays\"][:,1] > 0\n",
    "\n",
    "        for j in range(len(curr_daught)):\n",
    "            if( curr_alpha[j] and not curr_daught[j] in daughter_list):\n",
    "                daughter_list.append(curr_daught[j]) \n",
    "\n",
    "print(daughter_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 0: Fr-221 SiO2\n",
      "Writing 1: At-217 SiO2\n",
      "Writing 2: Bi-213 SiO2\n",
      "Writing 3: Tl-209 SiO2\n",
      "Writing 4: Pb-209 SiO2\n",
      "Writing 5: Tl-208 SiO2\n",
      "Writing 6: Pb-208 SiO2\n",
      "Writing 7: Bi-207 SiO2\n",
      "Writing 8: Pb-207 SiO2\n",
      "Writing 9: Ra-223 SiO2\n",
      "Writing 10: Rn-219 SiO2\n",
      "Writing 11: Po-215 SiO2\n",
      "Writing 12: Pb-211 SiO2\n",
      "Writing 13: Tl-207 SiO2\n",
      "Writing 14: Pb-212 SiO2\n",
      "Writing 15: He-4 SiO2\n",
      "Writing 16: Fr-221 Au\n",
      "Writing 17: At-217 Au\n",
      "Writing 18: Bi-213 Au\n",
      "Writing 19: Tl-209 Au\n",
      "Writing 20: Pb-209 Au\n",
      "Writing 21: Tl-208 Au\n",
      "Writing 22: Pb-208 Au\n",
      "Writing 23: Bi-207 Au\n",
      "Writing 24: Pb-207 Au\n",
      "Writing 25: Ra-223 Au\n",
      "Writing 26: Rn-219 Au\n",
      "Writing 27: Po-215 Au\n",
      "Writing 28: Pb-211 Au\n",
      "Writing 29: Tl-207 Au\n",
      "Writing 30: Pb-212 Au\n",
      "Writing 31: He-4 Au\n",
      "Writing 32: Fr-221 Ag\n",
      "Writing 33: At-217 Ag\n",
      "Writing 34: Bi-213 Ag\n",
      "Writing 35: Tl-209 Ag\n",
      "Writing 36: Pb-209 Ag\n",
      "Writing 37: Tl-208 Ag\n",
      "Writing 38: Pb-208 Ag\n",
      "Writing 39: Bi-207 Ag\n",
      "Writing 40: Pb-207 Ag\n",
      "Writing 41: Ra-223 Ag\n",
      "Writing 42: Rn-219 Ag\n",
      "Writing 43: Po-215 Ag\n",
      "Writing 44: Pb-211 Ag\n",
      "Writing 45: Tl-207 Ag\n",
      "Writing 46: Pb-212 Ag\n",
      "Writing 47: He-4 Ag\n",
      "Writing 48: Fr-221 tissue\n",
      "Writing 49: At-217 tissue\n",
      "Writing 50: Bi-213 tissue\n",
      "Writing 51: Tl-209 tissue\n",
      "Writing 52: Pb-209 tissue\n",
      "Writing 53: Tl-208 tissue\n",
      "Writing 54: Pb-208 tissue\n",
      "Writing 55: Bi-207 tissue\n",
      "Writing 56: Pb-207 tissue\n",
      "Writing 57: Ra-223 tissue\n",
      "Writing 58: Rn-219 tissue\n",
      "Writing 59: Po-215 tissue\n",
      "Writing 60: Pb-211 tissue\n",
      "Writing 61: Tl-207 tissue\n",
      "Writing 62: Pb-212 tissue\n",
      "Writing 63: He-4 tissue\n"
     ]
    }
   ],
   "source": [
    "## now generate the TRIM input files from the templates for the list of isotopes above\n",
    "importlib.reload(ar)\n",
    "\n",
    "material_list = [\"SiO2\", \"Au\", \"Ag\", \"tissue\"]\n",
    "recoil_energy = {\"NR\": 200, \"alpha\": 10000} ## keV\n",
    "energy_step_to_save = {\"NR\": 1000, \"alpha\": 50000} ## eV, step to save in EXYZ file\n",
    "slab_thickness = {\"NR\": {\"SiO2\": 2000, \"Au\": 1000, \"Ag\": 1000, \"tissue\": 3000}, ## angstroms, nucleus\n",
    "                  \"alpha\": {\"SiO2\": 2000000, \"Au\": 400000, \"Ag\": 600000, \"tissue\": 3000000}} ## angstroms, alpha\n",
    "num_events = 10000 ## number of events for each isotope and material\n",
    "\n",
    "fidx = 0\n",
    "for mat in material_list:\n",
    "\n",
    "    template_file = path + \"/TRIM_input_files/TRIM.IN_%s.txt\"%mat\n",
    "\n",
    "    with open(template_file, 'r') as tf:\n",
    "        template_lines = tf.readlines()\n",
    "\n",
    "    for iso in daughter_list:\n",
    "\n",
    "        if(iso == \"He-4\"):\n",
    "            tag = \"alpha\"\n",
    "        else:\n",
    "            tag = \"NR\"\n",
    "\n",
    "        output_file = path + \"/TRIM_input_files/TRIM.IN_%d\"%fidx\n",
    "        print(\"Writing %d: %s %s\"%(fidx, iso, mat))\n",
    "\n",
    "        with open(output_file, 'wt') as of:\n",
    "            \n",
    "            for lidx, l in enumerate(template_lines):\n",
    "\n",
    "                if lidx == 0: ## write the first line as a header unchanged\n",
    "                    of.write(template_lines[0])\n",
    "                    continue\n",
    "\n",
    "                ## update ion information\n",
    "                if template_lines[lidx - 1].startswith(\"Ion:\"):\n",
    "                    Z, A = ar.get_Z_A_for_iso(iso)\n",
    "                    curr_recoil_energy = recoil_energy[tag]\n",
    "                    ion_line = \"    %d    %d    %d    0    %d    1    %d\\n\"%(Z, A, curr_recoil_energy, num_events, num_events)\n",
    "                    of.write(ion_line)\n",
    "                elif template_lines[lidx - 1].startswith(\"Target material\"):\n",
    "                    new_start = \"%s (%d) into \"%(iso, recoil_energy[tag])\n",
    "                    newl = l[0] + new_start + l[14:]\n",
    "                    of.write(newl)\n",
    "                elif template_lines[lidx - 1].startswith(\"Diskfiles\"):\n",
    "                    save_line = \"                          0       0           0       0               0                               %d\\n\"%energy_step_to_save[tag]\n",
    "                    of.write(save_line)\n",
    "                elif template_lines[lidx - 2].startswith(\"Layer\"):\n",
    "                    lineparts = l.split()\n",
    "                    layer_num = int(lineparts[0])\n",
    "                    layer_name = \"\"\n",
    "                    last_idx = 1\n",
    "                    for part in lineparts[1:]:\n",
    "                        layer_name += part + \" \"\n",
    "                        last_idx += 1\n",
    "                        if part.endswith('\"'):\n",
    "                            break\n",
    "                    layer_line = \" %d      %s           %d \"%(layer_num, layer_name, slab_thickness[tag][mat])\n",
    "                    for part in lineparts[last_idx+1:]:\n",
    "                        layer_line += part + \" \"\n",
    "                    of.write(layer_line + \"\\n\")\n",
    "                else:\n",
    "                    of.write(l)\n",
    "\n",
    "        fidx += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code to run on windows computer to run TRIM jobs\n",
    "input_files = glob.glob(\"C:/SRIM/Sphere_Recoils_MC/TRIM_input_files/*\")\n",
    "\n",
    "replace_files = False\n",
    "\n",
    "destination_file = r\"C:/SRIM/TRIM.IN\"\n",
    "trim_path = r\"C:\\SRIM\"\n",
    "output_dir = r\"C:\\SRIM\\output_files_batch\"\n",
    "exyz_file = r\"C:\\SRIM\\SRIM Outputs\\EXYZ.txt\"\n",
    "\n",
    "for file in input_files:\n",
    "    if file.endswith('.txt'): continue\n",
    "\n",
    "    file_idx = file.split(\"_\")[-1]\n",
    "\n",
    "    if(os.path.isfile(output_dir + \"\\exyz_%s.txt\"%file_idx) and not replace_files):\n",
    "        print(output_dir + \"\\exyz_%s.txt\"%file_idx + \" already exists, skipping\")\n",
    "        continue\n",
    "\n",
    "    shutil.copy(file, destination_file)\n",
    "    print(\"Copied %s to %s\"%(file, destination_file)) \n",
    "\n",
    "    print(trim_path)\n",
    "    os.chdir(trim_path)\n",
    "    subprocess.call(\"./TRIM.exe\")\n",
    "\n",
    "    shutil.copy(exyz_file, output_dir + \"\\exyz_%s.txt\"%file_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Fr-221 in SiO2, event 10000\n",
      "Working on At-217 in SiO2, event 10000\n",
      "Working on Bi-213 in SiO2, event 10000\n",
      "Working on Tl-209 in SiO2, event 10000\n",
      "Working on Pb-209 in SiO2, event 10000\n",
      "Working on Tl-208 in SiO2, event 10000\n",
      "Working on Pb-208 in SiO2, event 10000\n",
      "Working on Bi-207 in SiO2, event 10000\n",
      "Working on Pb-207 in SiO2, event 10000\n",
      "Working on Ra-223 in SiO2, event 10000\n",
      "Working on Rn-219 in SiO2, event 10000\n",
      "Working on Po-215 in SiO2, event 10000\n",
      "Working on Pb-211 in SiO2, event 10000\n",
      "Working on Tl-207 in SiO2, event 10000\n",
      "Working on Fr-221 in Au, event 10000\n",
      "Working on At-217 in Au, event 10000\n",
      "Working on Bi-213 in Au, event 10000\n",
      "Working on Tl-209 in Au, event 10000\n",
      "Working on Pb-209 in Au, event 10000\n",
      "Working on Tl-208 in Au, event 10000\n",
      "Working on Pb-208 in Au, event 10000\n",
      "Working on Bi-207 in Au, event 10000\n",
      "Working on Pb-207 in Au, event 10000\n",
      "Working on Ra-223 in Au, event 10000\n",
      "Working on Rn-219 in Au, event 10000\n",
      "Working on Po-215 in Au, event 10000\n",
      "Working on Pb-211 in Au, event 10000\n",
      "Working on Tl-207 in Au, event 10000\n",
      "Working on Fr-221 in Ag, event 10000\n",
      "Working on At-217 in Ag, event 10000\n",
      "Working on Bi-213 in Ag, event 10000\n",
      "Working on Tl-209 in Ag, event 10000\n",
      "Working on Pb-209 in Ag, event 10000\n",
      "Working on Tl-208 in Ag, event 10000\n",
      "Working on Pb-208 in Ag, event 10000\n",
      "Working on Bi-207 in Ag, event 10000\n",
      "Working on Pb-207 in Ag, event 10000\n",
      "Working on Ra-223 in Ag, event 10000\n",
      "Working on Rn-219 in Ag, event 10000\n",
      "Working on Po-215 in Ag, event 10000\n",
      "Working on Pb-211 in Ag, event 10000\n",
      "Working on Tl-207 in Ag, event 10000\n",
      "working on Pb-212 starting at file  42\n",
      "Working on Pb-212 in SiO2, event 10000\n",
      "Working on Pb-212 in Au, event 10000\n",
      "Working on Pb-212 in Ag, event 10000\n"
     ]
    }
   ],
   "source": [
    "## parse exyz.txt files from TRIM and save in more efficient python data structure\n",
    "\n",
    "data_path = '/Users/dcmoore/Library/CloudStorage/GoogleDrive-david.c.moore@yale.edu/My Drive/yale/uspheres/alpha_recoils_Grimm/SRIM_Data/'\n",
    "\n",
    "data_dict = {}\n",
    "\n",
    "A_to_nm = 0.1 #convert angstrom to nm\n",
    "\n",
    "fidx = 0\n",
    "for mat in material_list:\n",
    "    for iso in daughter_list:\n",
    "\n",
    "        with open(data_path + \"exyz_%d.txt\"%fidx) as df:\n",
    "            lines = df.readlines()\n",
    "        \n",
    "        ## fix order for Pb-212\n",
    "        if(iso == \"Pb-212\"): continue\n",
    "\n",
    "        event_dict = {}\n",
    "        curr_event = -1\n",
    "        curr_traj_data = []\n",
    "        for l in lines:\n",
    "            if not l.startswith(\"0\"): continue \n",
    "\n",
    "            curr_dat = l.strip().split()\n",
    "            line_event = int(curr_dat[0])\n",
    "            if(curr_event == -1):\n",
    "                curr_event = line_event\n",
    "\n",
    "            ## fix rare issue with SRIM files\n",
    "            try:\n",
    "                test = [float(curr_dat[1]), float(curr_dat[2]), float(curr_dat[3]), float(curr_dat[4])]\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            if( abs(line_event - curr_event) < 0.1):\n",
    "                curr_traj_data.append([float(curr_dat[1]), float(curr_dat[2])*A_to_nm, float(curr_dat[3])*A_to_nm, float(curr_dat[4])*A_to_nm])\n",
    "            else:\n",
    "                if( line_event % 10000 == 0 ): \n",
    "                    print(\"Working on %s in %s, event %d\"%(iso, mat, line_event))\n",
    "                event_dict[curr_event] = np.array(curr_traj_data, dtype=float)\n",
    "                curr_event = line_event\n",
    "                curr_traj_data = [[float(curr_dat[1]), float(curr_dat[2])*A_to_nm, float(curr_dat[3])*A_to_nm, float(curr_dat[4])*A_to_nm],]\n",
    "\n",
    "        data_dict[iso + \"_\" + mat] = event_dict\n",
    "\n",
    "\n",
    "        fidx += 1\n",
    "\n",
    "print(\"working on Pb-212 starting at file \", fidx)\n",
    "for mat in material_list:\n",
    "    for iso in [\"Pb-212\"]:\n",
    "\n",
    "        with open(data_path + \"exyz_%d.txt\"%fidx) as df:\n",
    "            lines = df.readlines()\n",
    "\n",
    "        event_dict = {}\n",
    "        curr_event = -1\n",
    "        curr_traj_data = []\n",
    "        for l in lines:\n",
    "            if not l.startswith(\"0\"): continue \n",
    "\n",
    "            curr_dat = l.strip().split()\n",
    "            line_event = int(curr_dat[0])\n",
    "            if(curr_event == -1):\n",
    "                curr_event = line_event\n",
    "\n",
    "            ## fix rare issue with SRIM files\n",
    "            try:\n",
    "                test = [float(curr_dat[1]), float(curr_dat[2]), float(curr_dat[3]), float(curr_dat[4])]\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            if( abs(line_event - curr_event) < 0.1):\n",
    "                curr_traj_data.append([float(curr_dat[1]), float(curr_dat[2])*A_to_nm, float(curr_dat[3])*A_to_nm, float(curr_dat[4])*A_to_nm])\n",
    "            else:\n",
    "                if( line_event % 10000 == 0 ): \n",
    "                    print(\"Working on %s in %s, event %d\"%(iso, mat, line_event))\n",
    "                event_dict[curr_event] = np.array(curr_traj_data, dtype=float)\n",
    "                curr_event = line_event\n",
    "                curr_traj_data = [[float(curr_dat[1]), float(curr_dat[2])*A_to_nm, float(curr_dat[3])*A_to_nm, float(curr_dat[4])*A_to_nm],]\n",
    "\n",
    "        data_dict[iso + \"_\" + mat] = event_dict\n",
    "\n",
    "\n",
    "        fidx += 1\n",
    "\n",
    "with open(data_path + 'SRIM_MC_events.pkl', 'wb') as f:\n",
    "    pickle.dump(data_dict, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0000e+02,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "       [ 1.9869e+02,  7.7397e-01, -1.0687e-03, -9.1108e-04],\n",
       "       [ 1.9551e+02,  1.6790e+00, -9.5655e-03, -1.5251e-04],\n",
       "       [ 1.9286e+02,  2.1279e+00,  9.6251e-03, -3.8793e-02],\n",
       "       [ 1.9195e+02,  2.5759e+00, -1.2877e-02, -7.2104e-02],\n",
       "       [ 1.0702e+02,  3.0224e+00, -3.3246e-02, -1.1767e-01],\n",
       "       [ 1.0652e+02,  3.3274e+00,  1.6438e-01, -2.8267e-01],\n",
       "       [ 1.0142e+02,  3.9367e+00,  5.5659e-01, -6.1535e-01],\n",
       "       [ 1.0020e+02,  4.7535e+00,  1.3132e+00, -1.0191e+00],\n",
       "       [ 9.9721e+01,  5.0107e+00,  1.5826e+00, -1.1477e+00],\n",
       "       [ 9.7568e+01,  5.5232e+00,  2.1176e+00, -1.4136e+00],\n",
       "       [ 9.6778e+01,  6.5413e+00,  3.2581e+00, -1.7582e+00],\n",
       "       [ 9.3701e+01,  7.0591e+00,  3.8261e+00, -1.9033e+00],\n",
       "       [ 8.0629e+01,  7.2780e+00,  4.1307e+00, -2.0060e+00],\n",
       "       [ 7.9988e+01,  7.4705e+00,  4.4540e+00, -1.9747e+00],\n",
       "       [ 7.3029e+01,  7.6583e+00,  4.7771e+00, -1.9247e+00],\n",
       "       [ 7.2383e+01,  7.9160e+00,  5.0432e+00, -1.9233e+00],\n",
       "       [ 6.6693e+01,  8.4331e+00,  5.5704e+00, -1.8818e+00],\n",
       "       [ 6.5990e+01,  8.6923e+00,  5.8151e+00, -1.9561e+00],\n",
       "       [ 6.4439e+01,  9.2183e+00,  6.3065e+00, -2.0443e+00],\n",
       "       [ 6.3897e+01,  9.4814e+00,  6.5473e+00, -2.1045e+00],\n",
       "       [ 6.2661e+01,  1.0300e+01,  7.2321e+00, -2.2846e+00],\n",
       "       [ 6.1809e+01,  1.1058e+01,  7.9571e+00, -2.5358e+00],\n",
       "       [ 5.6271e+01,  1.1859e+01,  8.6254e+00, -2.7954e+00],\n",
       "       [ 5.5659e+01,  1.2164e+01,  8.8030e+00, -2.8041e+00],\n",
       "       [ 5.3627e+01,  1.2473e+01,  8.9710e+00, -2.7909e+00],\n",
       "       [ 3.7762e+01,  1.2750e+01,  9.1825e+00, -2.8020e+00],\n",
       "       [ 2.8305e+01,  1.4354e+01,  9.4552e+00, -2.6310e+00],\n",
       "       [ 2.7613e+01,  1.4922e+01,  9.5085e+00, -2.8775e+00],\n",
       "       [ 2.6812e+01,  1.5991e+01,  9.3677e+00, -3.4747e+00],\n",
       "       [ 2.5954e+01,  1.7570e+01,  9.1340e+00, -4.3914e+00],\n",
       "       [ 2.3903e+01,  1.8928e+01,  9.0008e+00, -5.0826e+00],\n",
       "       [ 2.2927e+01,  2.0836e+01,  9.4363e+00, -5.8541e+00],\n",
       "       [ 1.3322e+01,  2.1613e+01,  9.7028e+00, -6.2160e+00],\n",
       "       [ 4.1992e+00,  2.1858e+01,  9.6127e+00, -6.2929e+00],\n",
       "       [ 2.9569e+00,  2.1924e+01,  9.4012e+00, -6.3366e+00],\n",
       "       [ 1.7529e+00,  2.2321e+01,  9.0908e+00, -6.6814e+00],\n",
       "       [ 2.9000e-01,  2.2491e+01,  9.0981e+00, -7.0352e+00],\n",
       "       [ 0.0000e+00,  2.3076e+01,  8.8435e+00, -7.8248e+00]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict['Pb-212_SiO2'][9901]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### now do simulations for the alphas themselves"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e5e622b25f84b7135d4643d5fac34167b855b0a6d41d1f6695eb3e0f89a915df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
